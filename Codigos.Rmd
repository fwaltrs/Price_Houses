---
title: "Trabalho - LEA"
author: "Fernanda Waltrs, RA: 791437; 
         Luiza Graça, RA: 791328; 
         Milena Luzia, RA: 791394
         "
date: "Janeiro/2025"
output:
  pdf_document:
      latex_engine: xelatex
      fig_caption: yes
  html_document:
    df_print: paged
  word_document: default
  header-includes:
  - \usepackage{amsmath}
geometry: margin=2cm
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

O conjunto de dados usado neste estudo foi retirado do Kaggle e se refere aos preços de casas do Condado de King, EUA no site [House Sales in King County, USA](https://www.kaggle.com/datasets/harlfoxem/housesalesprediction), contendo 21.613 observações de maio de 2014 a maio de 2015. As covariáveis presentes são:

- **id:** identificador (chave)
- **date:** data
- **price:** preço do imóvel
- **bedrooms:** número de quartos
- **bathrooms:** número de banheiros
- **sqft_living:** área útil (em pés quadrados)
- **sqft_lot:** área do terreno (em pés quadrados)
- **floors:** número de andares
- **waterfront:** frente para a água
- **view:** vista
- **condition:** condição
- **grade:** nota (ou classificação)
- **sqft_above:** área acima (em pés quadrados)
- **sqft_basement:** área do porão (em pés quadrados)
- **yr_built:** ano de construção
- **yr_renovated:** ano de renovação
- **zipcode:** código postal (CEP)
- **lat:** latitude
- **long:** longitude
- **sqft_living15:** área útil média dos 15 vizinhos mais próximos (em pés quadrados)
- **sqft_lot15:** área do terreno média dos 15 vizinhos mais próximos (em pés quadrados)

# Importando as Bibliotecas

```{r, message = FALSE, warning=F}
library(ggplot2)
library(MASS)
library(BART)
library(readr)
library(glmnet)
library(knitr)
library(ggplot2)
library(reshape2)
library(ranger)
library(dplyr)
library(matrixStats)
library(tidyverse)
library(neuralnet)
library(keras3)
library(tensorflow)
```

# Importando a Base

```{r,message = FALSE,warning = FALSE}
base <- read_csv("H:/Meu Drive/10º SEMESTRE/LABORATORIO/Atividade 4/kc_house_data.csv/kc_house_data.csv")
print(colnames(base))
```

# Análise Descritiva
Vamos fazer uma análise descritiva sucinta dos dados para entender um pouco sobre as covariáveis. Os scripts abaixo trazem as informações de estatística como média, desvio padrão, mínimo, quantis e máximo das variáveis contínuas do banco (desconsiderando as datas, id e código postal). 


```{r, message = FALSE, warning=F}
kc_house_data <- base[, -c(1, 2, 15, 16, 17)]
```

```{r, message = FALSE, warning=F}
summary(kc_house_data[1:8])
```

```{r, message = FALSE, warning=F}
summary(kc_house_data[9:16])
```
Ao analisar as tabelas podemos ver que o valor do preços das casas (que será nossa variável resposta) varia entre $75$ Mil a $7,7$ Milhões, sendo que o primeiro quartil já representa o valor de $321950$, vemos que que a maioria dos imóveis da base são de médio-alto padrão.

As demais covariáveis, podemos destacar que o número médio de banheiro é em torno de $2$ e de quartos é $3$, geralmente os imóveis tem em torno de $1$ a $2$. As classificações deste imóveis em média valor $8$ e a área do terreno destes imóveis é em 15,107$m^2$.

A seguir, apresentaremos os boxplots dessas covariáveis como maneira de complementar a análise das tabelas acima, representados nas Figuras abaixo.

```{r, fig.width=5, fig.height=3, fig.cap="\\label{fig:boxplot2} Boxplots das variáveis contínuas."}

# Definir as variáveis contínuas
continuous_vars <- c('price', 'bedrooms', 'bathrooms', 'sqft_living',
                     'sqft_lot', 'floors')

# boxplots
par(mfrow = c(2, 3), mar = c(3, 3, 3, 1)) 
for (var in continuous_vars) {
    boxplot(kc_house_data[[var]], 
            main = var, 
            col = "purple", 
            cex.main = 1, 
            cex.lab = 1, 
            cex.axis = 1, 
            ylab = "", 
            xlab = "")
}
par(mfrow = c(1, 1))

```


```{r, fig.width=5, fig.height=3, fig.cap="\\label{fig:boxplot2} Boxplots das variáveis contínuas."}

continuous_vars <- c('condition', 'grade', 'sqft_above', 'sqft_basement', 
                     'lat', 'long', 'sqft_living15', 'sqft_lot15')

# boxplots
par(mfrow = c(2, 4), mar = c(3, 3, 3, 1))  
for (var in continuous_vars) {
  boxplot(kc_house_data[[var]], 
          main = var, 
          col = "purple", 
          ylab = "", 
         cex.main = 1, 
          cex.lab = 1, 
          cex.axis = 1) 
}
```

Alguns destaques: a variável resposta possui muitos outliers e uma menor dispersão dos dados devido o tamanho pequeno da caixa. Já o número de andares possui uma dispersão grande. Também podemos ver que a maior parte dos imóveis dessa base estão localizados em endereços com latitudes altas e longitudes baixas. 

A seguir, uma histograma da variável resposta.
```{r}
ggplot(kc_house_data, aes(x = price)) +
  geom_histogram(bins = 30, fill = "purple", color = "black") +
  labs(title = "Distribuição dos Preços de Casas",x = "Preço das Casas",y = "Frequência") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold"), 
    axis.title = element_text(size = 14), 
    axis.text = element_text(size = 12) 
  )
```


A seguir, iremos retirar as colunas de id, as datas e código postal. Também iremos fazer uma amostragem nos dados para fazer Data-Splitting. Separamos $70\%$ para a amostra de treino e $30\%$ para a amostra de teste.A variável resposta será o preço do imóvel (price).

```{r pressure, echo=FALSE}
set.seed(100)
split <- 
  sample(c("Treinamento", "Teste"),prob=c(0.7,0.3),size=nrow(kc_house_data),replace=TRUE)
table(split)  

treino = kc_house_data[split=="Treinamento",]
teste = kc_house_data[split=="Teste",]

Y_treino <- treino$price
X_treino <- treino[,-c(1)]
  
Y_teste <- teste$price
X_teste <- teste[,-c(1)]

```

# Item I
## BART

Agora, com a base dividida iremos implementar um estimador BART para prever a variável resposta - Preço das Casas. 

```{r}
set.seed(99)
post <- wbart(as.matrix(X_treino), as.matrix(Y_treino), as.matrix(X_teste), ndpost = 1000)
```

# Intervalos preditivos em 5 observações do conjunto teste

```{r}
means <- post$yhat.test.mean
std_dev <- sqrt(mean(post$sigma)^2 +
                  apply(post$yhat.test, 2, sd)^2)
lower_bound <- means - 1.96 * std_dev
upper_bound <- means + 1.96 * std_dev
```

```{r}
set.seed(7) 
Observation =  sample(1:dim(teste)[1], 5)

intervals_5 <- data.frame(
  Observation = 1:5,
  Lower_Bound = lower_bound[Observation],
  Mean = means[Observation],
  Upper_Bound = upper_bound[Observation],
  Real = Y_teste[Observation],
  Tamanho_Intervalo = upper_bound[Observation] - lower_bound[Observation]
)
intervals_5
```


Considerando os pontos azuis como as verdadeiras observações e rosas como as preditas, temos a seguinte relação: 

```{r}
ggplot(intervals_5, aes(x = Observation)) +
  geom_point(aes(y = Real), colour = "#1E88E5", size = 3) +  
  geom_line(aes(y = Mean), colour = "#D81B60", linewidth = 2) +  
  geom_ribbon(aes(ymin = Lower_Bound, ymax = Upper_Bound), fill = "grey20", alpha = 0.2) +  
  labs(x = "Observação", y = "Preço") +
  theme_bw() +
  theme(text = element_text(size = 14), 
        legend.title = element_blank(), 
        legend.position = "top")

```

## Tamanho médio delas no conjunto completo 

```{r}
predicao_conjunt_todo <- predict(post,as.matrix(kc_house_data[,-c(1)]))
```
```{r}
num_observacoes <- ncol(predicao_conjunt_todo)
medias <- colMeans(predicao_conjunt_todo)
print(length(medias))
print(num_observacoes)
```

```{r}
p = medias[split=="Teste"]
print(length(p))
```

```{r}
means <- p
std_dev <- sqrt(mean(sqrt(colVars(predicao_conjunt_todo[,split=="Teste"])))^2 + apply(predicao_conjunt_todo[,split=="Teste"], 2, sd)^2)
lower_bound <- means - 1.96 * std_dev
upper_bound <- means + 1.96 * std_dev
```

```{r}
intervals_5 <- data.frame(
  Observation = 1:5,
  Lower_Bound = lower_bound[Observation],
  Mean = p[Observation],
  Upper_Bound = upper_bound[Observation],
  Real = teste[Observation,1],
  Tamanho_Intervalo = upper_bound[Observation] - lower_bound[Observation]
)
intervals_5
```

```{r}
ggplot(intervals_5, aes(x = Observation)) +
  geom_point(aes(y = price), colour = "#1E88E5", size = 3) +  
  geom_line(aes(y = Mean), colour = "#D81B60", linewidth = 2) +  
  geom_ribbon(aes(ymin = Lower_Bound, ymax = Upper_Bound), fill = "grey20", alpha = 0.2) +  
  labs(x = "Observação", y = "Preço") +
  theme_bw() +
  theme(text = element_text(size = 14), 
        legend.title = element_blank(), 
        legend.position = "top")

```

Como conclusão, usando o conjunto completo o tamanho médio dos intervalos para as $5$ observações é menor, como vimos nas tabelas e gráficos. 

## RMSE, MAE e seus respectivos ICs

```{r}
ic = function(obs,predito){
     df = data.frame(rownames = c("risco" ,"var" ,"ic_superior" , "ic_inferior"),
                     RMSE = 0, MAE=0)
     SEQM = sqrt(mean((obs - predito)^2)) 
     w_bart <- (obs - predito)^2
     var_SEQM =  mean(w_bart - sqrt(mean(w_bart))) 
     
     ic_superior_SEQM = SEQM +  1.96*sqrt(var_SEQM/length(obs))
     ic_inferior_SEQM = SEQM - 1.96*sqrt(var_SEQM/length(obs)) 
     
     risco_abs = mean(abs(obs -  predito)) 
     w_bart <- abs(obs - predito)
     var_abs <- mean(abs(w_bart - mean(w_bart)))

     ic_superior_abs = risco_abs + 1.96 * sqrt(var_abs/length(obs)) 
     ic_inferior_abs = risco_abs - 1.96 * sqrt(var_abs/length(obs)) 
     
     df[1,2] = SEQM
     df[2,2] = var_SEQM
     df[3,2] = ic_superior_SEQM
     df[4,2] = ic_inferior_SEQM
     df[1,3] = risco_abs
     df[2,3] = var_abs
     df[3,3] = ic_superior_abs
     df[4,3] = ic_inferior_abs
     return(df)
}
ic_bart = ic(teste$price, as.numeric(post$yhat.test.mean))
ic_bart
```

# Item II: Rede Neural 
## NET 1 
```{r,message=F,warning=F}
tensorflow::set_random_seed(42)
X_treino_matriz <- as.matrix(X_treino)
Y_data = as.vector(Y_treino)

model1 <- keras_model_sequential() %>%
    layer_dense(units = 64, activation = "relu", input_shape = ncol(X_treino_matriz)) %>%  
    layer_dropout(rate = 0.3) %>%  # Regularização
    layer_dense(units = 32, activation = "relu") %>%  # Segunda camada
    layer_dense(units = 1)  


compile(model1,
          loss = "mse", 
          optimizer = optimizer_rmsprop(),
          metrics = "mae")  
  
model1 %>% fit(
  X_treino_matriz, Y_data,
  epochs = 100,
  batch_size = 32,
  validation_split = 0.2,
  verbose = 0
)
```

## NET 2 
```{r,message=F,warning=F}
tensorflow::set_random_seed(42)
X_treino_matriz <- as.matrix(X_treino)
Y_data = as.vector(Y_treino)

model2 <- keras_model_sequential() %>%
    layer_dense(units = 128, activation = "relu", input_shape = ncol(X_treino_matriz)) %>% 
    layer_dropout(rate = 0.3) %>%  # Regularização
    layer_dense(units = 32, activation = "relu") %>%  # Segunda camada
    layer_dense(units = 1)  


compile(model2,
          loss = "mse", 
          optimizer = optimizer_rmsprop(),
          metrics = "mae")  
  
model2 %>% fit(
  X_treino_matriz, Y_data,
  epochs = 100,
  batch_size = 32,
  validation_split = 0.2,
  verbose = 0
)
```

## NET 3 
```{r,message=F,warning=F}
tensorflow::set_random_seed(42)
X_treino_matriz <- as.matrix(X_treino)
Y_data = as.vector(Y_treino)

model3 <- keras_model_sequential() %>%
    layer_dense(units = 64, activation = "softmax", input_shape = ncol(X_treino_matriz)) %>%  
    layer_dropout(rate = 0.3) %>%  # Regularização
    layer_dense(units = 32, activation = "softmax") %>%  # Segunda camada
    layer_dense(units = 1)  


compile(model3,
          loss = "mse",  
          optimizer = optimizer_rmsprop(),
          metrics = "mae")
  
model3 %>% fit(
  X_treino_matriz, Y_data,
  epochs = 100,
  batch_size = 32,
  validation_split = 0.2,
  verbose = 0
)
```

Vamos avaliar qual rede neural é melhor para prever o preços das casas, para isso vamos calcular o RMSE, MAE e seus respectivos intervalos de confiança para o conjunto de teste: 

A primeira maneira foi usar uma função pronta que calcula já as métricas de perda (loss) e MAE. 

```{r,message=F,warning=F}
# Avaliar os modelos
X_teste_matriz <- as.matrix(X_teste)
result1 <- model1 %>% evaluate(X_teste_matriz, Y_teste)
result2 <- model2 %>% evaluate(X_teste_matriz, Y_teste)
result3 <- model3 %>% evaluate(X_teste_matriz, Y_teste)

print(result1)
print(result2)
print(result3)

```

Aplicando a função que construímos: 

```{r,message=F,warning=F}
X_teste_matriz <- as.matrix(X_teste)
rn_pred1=model1 %>% predict(X_teste_matriz)
rn_pred2=model2 %>% predict(X_teste_matriz)
rn_pred3=model3 %>% predict(X_teste_matriz)

ic1 <- ic(teste$price, rn_pred1)
ic2 <- ic(teste$price, rn_pred2)
ic3 <- ic(teste$price, rn_pred3)

print(ic1)
print(ic2)
print(ic3)
```

Optamos por escolher a primeira arquitetura NET 2 já que o MAE foi o menor entre as 3 arquiteturas analisadas. 

# Item III: Lasso e Floresta Aleatória

## Lasso

Primeiramente, ajustamos um lasso no conjunto de treino: 

```{r}
lasso <- glmnet::cv.glmnet(as.matrix(X_treino),
                           Y_treino,
                           alpha=1,
                           type.measure = "mse")
```

E calculamos as predições para o conjunto de teste: 

```{r,message=F,warning=F}
predicao_lasso <- predict(lasso, newx = as.matrix(X_teste),
                   type="class", s = "lambda.min")
```

Agora iremos calcular as medidas de desempenho para problemas de regressão como o RSME e MAE e seus respectivos intervalos de confiança. 

## RMSE, MAE e seus respectivos ICs

```{r}
ic_lasso = ic(teste$price, predicao_lasso)
ic_lasso
```

## Random Forest considerando os hiperparâmetros default

Agora, focaremos em Random Forest, esse método possui alguns hiperparâmetros como o mtry, número de árvores, etc. Neste problema, iremos ajustar o método com os  hiperparâmetros padrão para regressão, como 500 árvores e mtry sendo raiz quadrada do número de covariáveis.

```{r}
floresta <- ranger(
  formula         = Y_treino ~ ., 
  data            = X_treino, 
  importance      = "impurity",
  verbose         = TRUE,
  seed            = 100,
  classification  = F
)
```

E agora calculando as predições com o conjunto de teste: 

```{r}
pred_florestas = predict(floresta, data = teste)$predictions
```

Agora iremos calcular as medidas de desempenho para problemas de regressão como o RSME e MAE e seus respectivos intervalos de confiança. 

## RMSE, MAE e seus respectivos ICs

```{r}
ic_florestas = ic(teste$price, pred_florestas)
ic_florestas
```

# Comparação dos Modelos 

Agora iremos comparar os modelos em relação ao seu poder preditivo, para isso iremos comparar as métricas de RMSE, MAE e seus intervalos de confiança. 
Observe as tabelas e o gráfico abaixo (não construímos para o MAE porque não ficaria muito visual devido a amplitude pequena dele).

```{r}
## Gráfico de IC
r_teste_raiz = c(ic_bart[1,2],ic2[1,2],ic_lasso[1,2],ic_florestas[1,2])
superior_raiz = c(ic_bart[3,2],ic2[3,2],ic_lasso[3,2],ic_florestas[3,2])
inferior_raiz = c(ic_bart[4,2],ic2[4,2],ic_lasso[4,2],ic_florestas[4,2])
tamanho = c(ic_bart[3,2]-ic_bart[4,2],ic2[3,2]-ic2[4,2],ic_lasso[3,2]-ic_lasso[4,2],
            ic_florestas[3,2]-ic_florestas[4,2])

risco_seqm = data.frame(p=c("Bart","Rede Neural","Lasso","Florestas"),
                  erro=r_teste_raiz,superior=superior_raiz, inferior=inferior_raiz,tamanho=tamanho)
kable(head(risco_seqm, 11),caption = '\\label{tab: icmodelo}Medidas do IC dos modelos.',
      align = "cccc", digits = 4)
```


```{r,message=F,warning=F}
ggplot(data.frame(p=c("Bart","Rede Neural","Lasso","Florestas"),
                  erro=r_teste_raiz,superior=superior_raiz, inferior=inferior_raiz),
       aes(y=erro, x=p))+
  geom_errorbar(ymin = inferior_raiz, ymax = superior_raiz)+
  geom_point(size=3,color='#6699CC')+
  theme_bw(base_size = 9)+
  ylim(138000, 270000)+
  labs(y="RMSE",x='')+
  theme()
  
```

```{r}
## Gráfico de IC
r_teste_abs = c(ic_bart[1,3],ic2[1,3], ic_lasso[1,3],ic_florestas[1,3])
superior_abs = c(ic_bart[3,3],ic2[3,3],ic_lasso[3,3],ic_florestas[3,3])
inferior_abs = c(ic_bart[4,3],ic2[4,3],ic_lasso[4,3],ic_florestas[4,3])
tamanho = c(ic_bart[3,3]-ic_bart[4,3],ic2[3,3]-ic2[4,3],ic_lasso[3,3]-ic_lasso[4,3],
            ic_florestas[3,3]-ic_florestas[4,3])

risco_mae = data.frame(p=c("Bart","Rede Neural","Lasso","Florestas"),
                  erro=r_teste_abs,superior=superior_abs, inferior=inferior_abs)
kable(head(risco_mae, 11),caption = '\\label{tab: icmodelo}Medidas do IC dos modelos.',
      align = "cccc", digits = 4)
```


Como conclusão, analisando os resultados preditivos o modelo que teve o melhor desempenho preditivo em relação ao RMSE foi o BART (143078.7) e segundo o MAE também foi o BART (74820.71). Além disso, ao analisar os intervalos de confiança podemos observar que realmente o BART se destaca com a menor amplitude para ambos os erros, mas random forest também se destaca com valores próximos dele. 